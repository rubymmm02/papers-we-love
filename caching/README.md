# Caching

* [:scroll:](a-constant-algorithm-for-implementing-the-lfu-cache-eviction-scheme.pdf) [An O(1) algorithm for implementing the LFU cache eviction scheme](https://github.com/papers-we-love/papers-we-love/blob/master/caching/a-constant-algorithm-for-implementing-the-lfu-cache-eviction-scheme.pdf) by Prof. Ketan Shah, Anirban Mitra, Dhruv Matani

* [:scroll:](2q-a-low-overhead-high-performance-buffer-management-replacement-algorithm.pdf) [2Q: A Low Overhead High Performance Buffer Management Replacement Algorithm](http://www.vldb.org/conf/1994/P439.PDF) by Theodore Johnson and Dennis Shasha
In computing, a cache /ˈkæʃ/ KASH,[1] is a hardware or software component that stores data so future requests for that data can be served faster; the data stored in a cache might be the result of an earlier computation, or the duplicate of data stored elsewhere. A cache hit occurs when the requested data can be found in a cache, while a cache miss occurs when it cannot. Cache hits are served by reading data from the cache, which is faster than recomputing a result or reading from a slower data store; thus, the more requests can be served from the cache, the faster the system performs.
